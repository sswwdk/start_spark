{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91bc78b-c953-4b36-829f-ee3c93176f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "MAX_MEMORY = '8g'\n",
    "spark = SparkSession.builder.appName(\"taxi-fare-prediction_2nd\")\\\n",
    "        .config('spark.driver.memory',MAX_MEMORY) \\\n",
    "        .config('spark.executor.memory',MAX_MEMORY)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf429170-3577-4246-a636-8a5cd5093f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/learning_spark_data/trips/*.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, 'learning_spark_data', 'trips', '*.csv')\n",
    "trip_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e34cb3f-b467-4eea-9af8-dc1fdf3fc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = f\"file:///{trip_data_path.replace(os.sep,'/')}\"\n",
    "file_path\n",
    "\n",
    "trip_df = spark.read.csv(trip_data_path, inferSchema=True, header=True)\n",
    "trip_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5694d813-5079-47a7-a9f1-d7efbd0f66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.createOrReplaceTempView('trips')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "    total_amount\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57acd2ac-0b52-4757-9451-22cb814fd61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|               138|                265|         16.5|          0|     Monday|       70.07|\n",
      "|              1|                68|                264|         1.13|          0|     Monday|       11.16|\n",
      "|              1|               239|                262|         2.68|          0|     Monday|       18.59|\n",
      "|              1|               186|                 91|         12.4|          0|     Monday|        43.8|\n",
      "|              2|               132|                265|          9.7|          0|     Monday|        32.3|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = spark.sql(query)\n",
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f86f81-3941-4df3-b77d-61eee6dbda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 쪼개기 train 8 : 2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "936b6cd1-21d6-454b-864a-3f4af0dbf030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|passenger_count|pickup_location_id|dropoff_location_id|trip_distance|pickup_time|day_of_week|total_amount|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "|              0|                 4|                  4|          0.1|         18|   Saturday|         6.3|\n",
      "|              0|                 4|                 79|          0.7|         12|    Tuesday|         8.8|\n",
      "|              0|                 4|                 79|          0.7|         23|   Saturday|       12.35|\n",
      "|              0|                 4|                 79|          0.9|         14|     Monday|         9.8|\n",
      "|              0|                 4|                114|          0.9|         18|     Friday|        10.8|\n",
      "+---------------+------------------+-------------------+-------------+-----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train,test split 8:2, seed 1\n",
    "train_data, test_data = data_df.randomSplit([0.8, 0.2], seed=1)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6613a5-d601-4812-b4fd-278c5d7578c4",
   "metadata": {},
   "source": [
    "# 파이프라인 생성   \n",
    "- 전처리 과정을 각 스테이지로 정의해서 쌓는다\n",
    "- onehotencoding > 'pickup_location_id', 'dropoff_location_id', 'day_of_week' 3컬럼 숫자 크기가 의미있는 것이 아니기 때문에.\n",
    "- 범주형 ['pickup_location_id', 'dropoff_location_id', 'day_of_week']\n",
    "- 수치형 ['passenger_count','trip_distance','pickup_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec504226-9e20-4498-a90f-72d9f7ea7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580ae10f-7037-43aa-a4ac-4a304b317485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f200f0-e459-4e05-bbbe-5731c9c86164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_d3a0212a9a87,\n",
       " OneHotEncoder_a3ca55c261a1,\n",
       " StringIndexer_7c398055c211,\n",
       " OneHotEncoder_beb32205391d,\n",
       " StringIndexer_3f115ff4a61d,\n",
       " OneHotEncoder_f51ea6989c84]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형 features StringIndex + OnehotEncoding\n",
    "cat_features = ['pickup_location_id', 'dropoff_location_id', 'day_of_week']\n",
    "stages = []\n",
    "\n",
    "for cat in cat_features:\n",
    "    cat_index = StringIndexer(inputCol=cat, outputCol=cat+'_idx').setHandleInvalid('keep') # .setHandleInvalid('keep') : 변환 안되는게 있으면  keep해\n",
    "    onehot_encode = OneHotEncoder(inputCols=[cat_index.getOutputCol()], outputCols=[cat+'_onehot']) # inputCols 안에 _idx col 들어감/ outpurCols - postfix\n",
    "    stages += [cat_index,onehot_encode] # collist : 컬럼 목록\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e4fe4f-ac63-43f1-913d-cc17c42b17d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_d3a0212a9a87,\n",
       " OneHotEncoder_a3ca55c261a1,\n",
       " StringIndexer_7c398055c211,\n",
       " OneHotEncoder_beb32205391d,\n",
       " StringIndexer_3f115ff4a61d,\n",
       " OneHotEncoder_f51ea6989c84,\n",
       " VectorAssembler_e4bc664c3a76,\n",
       " StandardScaler_b6ac73987183,\n",
       " VectorAssembler_3c344e9ccabc,\n",
       " StandardScaler_c6baebad40cd,\n",
       " VectorAssembler_6f58588713d9,\n",
       " StandardScaler_866f1820daff]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수치형 features VectorAssembler + standardScaler\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "\n",
    "num_features = ['passenger_count','trip_distance','pickup_time']\n",
    "\n",
    "for num in num_features:\n",
    "    num_assembler = VectorAssembler(inputCols=[num], outputCol=num+'_vector')\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=num+'_scaled')\n",
    "    stages += [num_assembler, num_scaler]\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354ddf1-31e3-49b2-b525-d377b85ec509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479def6f-5f52-47dc-84a3-bfaea24cead1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler_input = [cat+'_onehot' for cat in cat_features] + [num+'_scaled' for num in num_features]\n",
    "assembler_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ee992d-1597-48d1-ae47-c06afa9c8863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_d3a0212a9a87,\n",
       " OneHotEncoder_a3ca55c261a1,\n",
       " StringIndexer_7c398055c211,\n",
       " OneHotEncoder_beb32205391d,\n",
       " StringIndexer_3f115ff4a61d,\n",
       " OneHotEncoder_f51ea6989c84,\n",
       " VectorAssembler_e4bc664c3a76,\n",
       " StandardScaler_b6ac73987183,\n",
       " VectorAssembler_3c344e9ccabc,\n",
       " StandardScaler_c6baebad40cd,\n",
       " VectorAssembler_6f58588713d9,\n",
       " StandardScaler_866f1820daff,\n",
       " VectorAssembler_0d1f48628b7b]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_input, outputCol='feature_vector')\n",
    "stages += [assembler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7de06d-f91d-4dbf-b74b-d339c8d6f7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vector: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transform = pipeline.fit(train_data)\n",
    "fitted_transform.transform(train_data)\n",
    "vtrain_df = fitted_transform.transform(train_data)\n",
    "vtrain_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "660cade4-31cb-4b87-9d42-586972509fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      feature_vector|\n",
      "+--------------------+\n",
      "|(533,[62,311,527,...|\n",
      "|(533,[62,280,526,...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vtrain_df.select('feature_vector').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc8681-4194-4339-94ca-b57de66bab26",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3cc0511-da62-47c1-914c-63e1e8645beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(\n",
    "    maxIter=50, solver='normal',labelCol='total_amount', featuresCol='feature_vector'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d260d0c3-f1cc-4741-8222-91c93e5282c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e43ad55-cc35-42b6-84ab-f14804f02710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터도 변환\n",
    "vtest_df = fitted_transform.transform(test_data)\n",
    "# 테스트 데이터로 예측\n",
    "pred = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59bcef12-95fe-4b57-adb9-df834d1c6042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[passenger_count: int, pickup_location_id: int, dropoff_location_id: int, trip_distance: double, pickup_time: int, day_of_week: string, total_amount: double, pickup_location_id_idx: double, pickup_location_id_onehot: vector, dropoff_location_id_idx: double, dropoff_location_id_onehot: vector, day_of_week_idx: double, day_of_week_onehot: vector, passenger_count_vector: vector, passenger_count_scaled: vector, trip_distance_vector: vector, trip_distance_scaled: vector, pickup_time_vector: vector, pickup_time_scaled: vector, feature_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58605f73-b132-49ac-8954-fe3be57f4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|total_amount|        prediction|\n",
      "+------------+------------------+\n",
      "|       10.55|12.695522792729275|\n",
      "|        13.3|14.450558014776915|\n",
      "|        21.3|21.108271361254218|\n",
      "+------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select('total_amount','prediction').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "499661e5-a2aa-44f1-a23a-4c659fd44b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80849012500813, 5.6485201652667625)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.r2, model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d8078c5-5ecc-4b45-9fef-686db6832605",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c2aa1-61e4-47ac-9750-285ce265bb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
